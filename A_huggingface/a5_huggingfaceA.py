# -*- coding: utf-8 -*-
"""A5_huggingface.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16S2rZUxP7YTuKasWxo63hZE7ghSoJRjj
"""

''' License
Joshua K. Cage 저자 임선집 옮긴이의 101가지 문제로 배우는 딥러닝 허깅페이스 트랜스포머 with 파이토치(Python Transformers By Huggingface Hands On:)의 예제를 실행한 것임을 알립니다.    This code has been brought from the GitHub repository below and has been slightly modified.:https://github.com/jasonyim2/book3/blob/main/Transformers%2027-36.ipynb
'''

# PIP
!pip install transformers
!pip install ftfy ## 새주석: 텍스트 처리 라이브러리 (Fix Text For You)

# PIL = Pillow 라이브러리(PIL)를 사용하여 이미지 불러오기
from PIL import Image

import matplotlib.pyplot as plt

## 새주석: 로컬 이미지 파일 가져오기
img_path = "/content/images/test_img.jpg"
image = Image.open(img_path)
image

# 모델 및 프로세서 불러오기
## 새주석: Load a Pre-trained Model: CLIP
from transformers import CLIPProcessor, CLIPModel

model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# 텍스트를 리스트 타입으로 입력
candidates = [
    "a photo of fruits in a box",
    "a photo of Devices designed by Apple Co.",
    "a strawberry",
    "three cats lying on the couch",
    "There are apples that look good."
    ]

# 프로세서(ClIPPprocessor)에 텍스트 및 이미지를 입력하여 인코딩
inputs = processor(text=candidates, images=image, return_tensors="pt", padding=True)

# inputs 출력
inputs

# 인코딩한 이미지 출력
plt.imshow(inputs['pixel_values'][0][0]);

# inputs['pixel_values'] 차원 확인
inputs['pixel_values'].shape # 새주석: [1, 3, 224, 224]

# 인코딩한 이미지 출력. 인덱스를 [0][1]로 변경
plt.imshow(inputs['pixel_values'][0][1])

# 인코딩된 텍스트 출력
inputs['input_ids'][0] ## 새주석: Tensor로 출력됨

# 위의 결과를 디코딩한 텍스트 출력
processor.tokenizer.decode(inputs['input_ids'][0])

# 모델을 eval 모드로 전환
## 새주석: evaluate = 평가모드로 전환
model.eval()

# **inputs에서의 ** 표시는 inputs 변수가 키(key)와 값(value)로 이루어져 있을 때
# input 변수에 담긴 키와 값을 모두 모델에 입력하는 용도임
outputs = model(**inputs)

# 출력물 outputs의 키(key) 출력
outputs.keys()

logits_per_image = outputs.logits_per_image
print(logits_per_image)

# logits_per_image에 담긴 값을 입력값 행별로(each row -> dim=1) 소프트맥스 함수에 투입
probs = logits_per_image.softmax(dim=1)

import torch

# 변수 probs에 담긴 값 중에 최고값의 인덱스를 argmax로 찾고
# item()을 통해 레이블 즉 제목을 출력
# 그 결과가 cadidates의 인덱스 값이 됨
print(candidates[torch.argmax(probs).item()])